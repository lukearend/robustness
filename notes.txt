what's where:
    tab 0: local git
    tab 1: dgx imagenet 4
        screen -rd tf
            0: git pull origin master
            1: bash tb.sh
            2: sbatch --array=4 train-dgx.sh
            3: tail -f out/4.out
            4: watch -n 30 squeue
            5: ls
    tab 2: polestar imagenet 3 and tensorboard for 0,1,3
        screen -rd tf
            0: git pull origin master
            1: bash tb.sh
            2: sbatch --qos=cbmm --array=3 train-om.sh
            3: tail -f out/3.out
            4: watch -n 30 squeue --user larend
            5: ls
    tab 3: polestar-old imagenet 2,1
        screen -rd tf
            0: git pull origin master
            1: bash train-polestar-old.sh 2 (gpu-16)
            2: bash train-polestar-old.sh 1 (gpu-17)
            3: watch -n 30 nvidia-smi (gpu-16)
            4: watch -n 30 nvidia-smi (gpu-17)
            5: ls
    tab 4: local tensorboard
        screen -rd tf
            0: ssh -L 6006:dgx1:6050 larend@dgx1.mit.edu (imagenet 4)
            1: ssh -L 6007:polestar:6050 larend@polestar.mit.edu (imagenet 0,1,2,3)

    tab 5: polestar cifars
        screen -rd cifar
            0: git pull origin master
            1: bash tb.sh 6051
            2: sbatch --qos=cbmm --array=0-9 train-om.sh
            4: tail -f out/*.out
            5: watch -n 30 squeue --user larend
            6: ls


training notes:
    05-11-2018:
        -imagenet 4 in dgx
        -imagenet 3 in polestar
        -cifar10 in om
            -0,1,2,3,4 done
        -cifar10-no-bn in om
            -0,1,2,3,4 done
        -imagenet 0 in polestar-old:gpu-16
        -imagenet 1 in polestar-old:gpu-17

    05-13-2018:
        -imagenet 4 in dgx
        -imagenet 3 in om qos
        imagenet 0,1 in polestar-old:gpu-16,17
        -imagenet 0 finished in polestar-old, so I copied the current checkpoints of imagenet 3 from polestar to polestar-old and tried running it there to see if it runs any faster there. I'm tracking it with tensorboard so I'll check back on it in a few hours to see if that has any advantage in speed over training the model in om.
            -found: it trains almost twice as fast. going to keep training it in polestar.
            -in polestar, it goes 1.061 steps/sec; in polestar-old, 1.921; in om with no cpu request, 0.67; in om with cpu request, 2.017
        -since imagenet 3 sped up so much by being placed in polestar, I realized that dgx is going unreasonably slowly. realized that it's because it was just using one CPU and I didn't ask for more cores in the slurm allocation. just restarted it with 80 cores and now imagenet 4 seems to be going twice as fast.
        -going to bed with the following configuration: imagenet 4 in dgx, imagenet 3 in om-qos, imagenet 2,1 in polestar old.
        -found that the cifar results were lower than expected. probably because I upsampled cifar to 224 and instead of downsizing the model to fit the 32x32 images as in the He paper. going to retrain the cifar models as in the He paper and see if that improves at all. will copy the current results to a new directory naming them as old (224).
            -to do monday: make a non-backwards compatible change to the cifar training and dataset where it loads the 32x32 images and small models only, and retrain in om-qos
    05-14-2018:
        -to do:
            -babysit the models currently training
            -cifar models
                -rewrite code
                    -change cifar datasets to 32x32
                    -change graph to build mini resnet if dataset is cifar
                -retrain
                    -transfer current files to an archive with descriptive name
                    -retrain in om-qos
            -check how I can help xavi with evaluation code
            -rest of day, work on new metric
            -longer term, white box RF method
        -I put all the cifars (bn and no-bn) into one group of 10 models instead of two groups of 5 models.
        -to do: get robustness code running for my models


training results for cifar-224x224
    cifar10:
        00000:
            precision_at_one: 0.8198
            precision_at_five: 0.9856
        00001:
            precision_at_one: 0.8378
            precision_at_five: 0.9882
        00002:
            precision_at_one: 0.8532
            precision_at_five: 0.9904
        00003:
            precision_at_one: 0.8636
            precision_at_five: 0.992
        00004:
            precision_at_one: 0.846
            precision_at_five: 0.9906

    cifar10-no-bn:
        00000:
            precision_at_one: 0.51
            precision_at_five: 0.9284
        00001:
            precision_at_one: 0.6132
            precision_at_five: 0.9596
        00002:
            precision_at_one: 0.574
            precision_at_five: 0.9476
        00003:
            precision_at_one: 0.1628
            precision_at_five: 0.5892
        00004:
            precision_at_one: 0.5294
            precision_at_five: 0.9308
